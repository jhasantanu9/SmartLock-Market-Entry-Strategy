{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1\n",
      "Scraping page 2: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2\n",
      "Scraping page 3: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3\n",
      "Scraping page 4: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=4\n",
      "Scraping page 5: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=5\n",
      "Scraping page 6: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=6\n",
      "Scraping page 7: https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=7\n",
      "Error fetching the product page: 500 Server Error: Internal Server Error for url: https://www.flipkart.com/jenix-tthotel-lock-card-encoder-13-56mhz-suitable-smart-door/p/itm0f0d7e4661c85?pid=SLOGVMSYGXFZQXPD&lid=LSTSLOGVMSYGXFZQXPDCB2KJG&marketplace=FLIPKART&q=Smart+Lock&store=igc%2Fu0f&srno=s_6_235&otracker=search&otracker1=search&fm=organic&iid=ebf2968d-0f30-4829-aae2-c1a33cd1da7e.SLOGVMSYGXFZQXPD.SEARCH&ppt=None&ppn=None&ssid=r592risx4g0000001733553274495&qH=c64d40479fa2d4ff\n",
      "Data has been saved to product_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_flipkart_products(base_url, start_page, end_page):\n",
    "    try:\n",
    "        # Headers to mimic a browser visit\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "\n",
    "        # Use a session to manage cookies\n",
    "        session = requests.Session()\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        all_products = []\n",
    "        current_rank = 1  # Initialize rank starting at 1\n",
    "\n",
    "        for page in range(start_page, end_page + 1):\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            print(f\"Scraping page {page}: {url}\")\n",
    "            response = session.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # Find all divs that potentially contain product links\n",
    "            product_divs = soup.find_all(\"div\", class_=\"_75nlfW\")\n",
    "\n",
    "            for parent_div in product_divs:\n",
    "                # Find all child divs with a specific structure containing product links\n",
    "                child_divs = parent_div.find_all(\"div\", recursive=False)\n",
    "                for div in child_divs:\n",
    "                    product_link = div.find(\"a\")\n",
    "                    if product_link and product_link.has_attr(\"href\"):\n",
    "                        product_url = \"https://www.flipkart.com\" + product_link[\"href\"]\n",
    "                        all_products.append({\"Rank\": current_rank, \"Product URL\": product_url})\n",
    "                        current_rank += 1\n",
    "\n",
    "        return all_products\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching the URL:\", e)\n",
    "        return []\n",
    "    \n",
    "def scrape_product_details(product_url, rank):\n",
    "    try:\n",
    "        # Headers to mimic a browser visit\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "\n",
    "        # Send a GET request to the product page\n",
    "        response = requests.get(product_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extract the desired details\n",
    "        product_name = soup.find(\"span\", class_=\"VU-ZEz\").get_text(strip=True) if soup.find(\"span\", class_=\"VU-ZEz\") else \"N/A\"\n",
    "        rating = float(soup.find(\"div\", class_=\"XQDdHH\").get_text(strip=True)) if soup.find(\"div\", class_=\"XQDdHH\") else 0.0\n",
    "        rating_review_text = soup.find(\"span\", class_=\"Wphh3N\").get_text(strip=True) if soup.find(\"span\", class_=\"Wphh3N\") else \"0 Ratings & 0 Reviews\"\n",
    "        rating_count = int(rating_review_text.split(\" Ratings\")[0]) if \"Ratings\" in rating_review_text else 0\n",
    "        review_count = int(rating_review_text.split(\"&\")[1].split(\" Reviews\")[0].strip()) if \"&\" in rating_review_text else 0\n",
    "        price = int(soup.find(\"div\", class_=\"Nx9bqj CxhGGd\").get_text(strip=True).replace('â‚¹', '').replace(',', '')) if soup.find(\"div\", class_=\"Nx9bqj CxhGGd\") else 0\n",
    "        brand_element = soup.find(\"td\", class_=\"Izz52n col col-9-12\", attrs={\"def\": \"\"})\n",
    "        brand = brand_element.find(\"li\", class_=\"HPETK2\").get_text(strip=True) if brand_element and brand_element.find(\"li\", class_=\"HPETK2\") else \"N/A\"\n",
    "        \n",
    "        return {\n",
    "            \"Product name\": product_name,\n",
    "            \"Brand name\": brand,\n",
    "            \"Price\": price,\n",
    "            \"Rating\": rating,\n",
    "            \"Rating count\": rating_count,\n",
    "            \"Review count\": review_count,\n",
    "            \"Rank\": rank,\n",
    "            \"URL\": product_url\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching the product page:\", e)\n",
    "        return {}\n",
    "\n",
    "def save_to_csv(products, filename=\"product_data.csv\"):\n",
    "    keys = products[0].keys() if products else []\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for product in products:\n",
    "            writer.writerow(product)\n",
    "\n",
    "# Base URL for scraping\n",
    "base_url = \"https://www.flipkart.com/search?q=Smart+Lock&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off\"\n",
    "\n",
    "# Call the scraper function for pages 1 to 7\n",
    "product_data = scrape_flipkart_products(base_url, 1, 7)\n",
    "\n",
    "# Visit each product URL and scrape detailed information\n",
    "all_product_details = []\n",
    "for product in product_data:\n",
    "    product_url = product['Product URL']\n",
    "    rank = product['Rank']\n",
    "    details = scrape_product_details(product_url, rank)\n",
    "    if details:\n",
    "        all_product_details.append(details)\n",
    "\n",
    "# Save the details to a CSV file\n",
    "save_to_csv(all_product_details)\n",
    "print(\"Data has been saved to product_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
